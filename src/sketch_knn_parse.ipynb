{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from math import ceil\n",
    "from itertools import count\n",
    "\n",
    "from sketch_io import train_data, valid_data\n",
    "\n",
    "# Folders for storage/retrival\n",
    "main_directory  = '../'\n",
    "checkpoints_directory = main_directory + 'checkpts/'\n",
    "features_directory    = main_directory + 'features/'\n",
    "tr_labels_dir = features_directory + 'tr_labels.npy'\n",
    "ev_labels_dir = features_directory + 'ev_labels.npy'\n",
    "tr_sketches_dir = features_directory + 'tr_sketches.npy'\n",
    "ev_sketches_dir = features_directory + 'ev_sketches.npy'\n",
    "\n",
    "# Feature choices\n",
    "NUM_SAMPLES = 1000000\n",
    "BATCH_SIZE  =     400\n",
    "NUM_TRAIN_BATCHES = ceil(NUM_SAMPLES / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (keys,     np.uint64), \n",
    "# (lengths,  np.uint16), \n",
    "# (sketches, np.uint8), \n",
    "# (labels,   np.uint16))]\n",
    "names = ['keys', 'lengths', 'sketches', 'labels']\n",
    "tr_filenames = [features_directory + 'tr_' + name + '.npy' for name in names]\n",
    "ev_filenames = [features_directory + 'ev_' + name + '.npy' for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "Storing sketches to np\n",
      "Step     200\n",
      "Step     400\n",
      "Step     600\n",
      "Step     800\n",
      "Step    1000\n",
      "Step    1200\n",
      "Step    1400\n",
      "Step    1600\n",
      "Step    1800\n",
      "Step    2000\n",
      "Step    2200\n",
      "Step    2400\n",
      "Step     200\n",
      "Step     400\n",
      "Step     600\n",
      "Step     800\n",
      "Step    1000\n",
      "Step    1200\n",
      "Step    1400\n",
      "Step    1600\n",
      "Step    1800\n",
      "Step    2000\n",
      "Step    2200\n",
      "Step    2400\n",
      "Step    2600\n",
      "Step    2800\n",
      "Step    3000\n",
      "Step    3200\n",
      "Step    3400\n",
      "Step    3600\n",
      "Step    3800\n",
      "Step    4000\n",
      "Step    4200\n",
      "Finished epoch\n",
      "Storing to file ../features/tr_keys.npy. Data shape: (1000000,)\n",
      "Storing to file ../features/tr_lengths.npy. Data shape: (1000000,)\n",
      "Storing to file ../features/tr_sketches.npy. Data shape: (1000000, 300, 3)\n",
      "Storing to file ../features/tr_labels.npy. Data shape: (1000000,)\n",
      "Storing to file ../features/ev_keys.npy. Data shape: (1700000,)\n",
      "Storing to file ../features/ev_lengths.npy. Data shape: (1700000,)\n",
      "Storing to file ../features/ev_sketches.npy. Data shape: (1700000, 300, 3)\n",
      "Storing to file ../features/ev_labels.npy. Data shape: (1700000,)\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# Write images & labels to file #\n",
    "#################################\n",
    "\n",
    "tr_key, _, tr_length, tr_sketch, tr_label = train_data(batch_size=BATCH_SIZE, epochs=1, max_seqlen=300)\n",
    "ev_key, _, ev_length, ev_sketch, ev_label = valid_data(batch_size=BATCH_SIZE, epochs=1, max_seqlen=300)\n",
    "\n",
    "def get_np_arrays(key_op, length_op, sketch_op, label_op, num_to_take=None):\n",
    "    keys, lengths, sketches, labels = [], [], [], []\n",
    "    num_batches = NUM_TRAIN_BATCHES if num_to_take else None\n",
    "    with tf.Session() as sess: \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        \n",
    "        for i in count():\n",
    "            if (i+1) % 200 == 0: print(\"Step {:7d}\".format(i+1))\n",
    "            try:\n",
    "                keys_out, lengths_out, sketches_out, labels_out = \\\n",
    "                    sess.run([key_op, length_op, sketch_op, label_op])\n",
    "                keys.append(keys_out)\n",
    "                lengths.append(lengths_out)\n",
    "                sketches.append(sketches_out)\n",
    "                labels.append(labels_out)\n",
    "                \n",
    "                if num_to_take: # Stop early?\n",
    "                    if len(keys) > ceil(num_to_take / BATCH_SIZE): \n",
    "                        return (np.concatenate(v).astype(dtype)[:num_to_take] \\\n",
    "                                for (v,dtype) in ((keys,     np.uint64), \n",
    "                                                  (lengths,  np.uint16), \n",
    "                                                  (sketches, np.uint8), \n",
    "                                                  (labels,   np.uint16)))\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"Finished epoch\")\n",
    "                return (np.concatenate(v).astype(dtype) \\\n",
    "                                for (v,dtype) in ((keys,     np.uint64), \n",
    "                                                  (lengths,  np.uint16), \n",
    "                                                  (sketches, np.uint8), \n",
    "                                                  (labels,   np.uint16)))\n",
    "\n",
    "def store_to_file(filenames, data):\n",
    "    for fname, val in zip(filenames, data):\n",
    "        print(\"Storing to file {}. Data shape: {}\".format(fname, val.shape))\n",
    "        np.save(fname, val)\n",
    "        \n",
    "# Have our solutions already?\n",
    "if any([not os.path.exists(d) for d in tr_filenames + ev_filenames]):\n",
    "    if not os.path.exists(features_directory):\n",
    "        os.makedirs(features_directory)\n",
    "    print(\"Storing sketches to np\")\n",
    "    tr_data = get_np_arrays(tr_key, tr_length, tr_sketch, tr_label, num_to_take=NUM_SAMPLES)\n",
    "    ev_data = get_np_arrays(ev_key, ev_length, ev_sketch, ev_label)\n",
    "    \n",
    "    store_to_file(tr_filenames, tr_data)\n",
    "    store_to_file(ev_filenames, ev_data)\n",
    "    print(\"Finished\")\n",
    "\n",
    "else:\n",
    "    print(\"Already parsed the sketches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data, ev_data = {}, {}\n",
    "\n",
    "for (name, tr_file) in zip(names, tr_filenames):\n",
    "    tr_data[name] = np.load(tr_file)\n",
    "\n",
    "for (name, ev_file) in zip(names, ev_filenames):\n",
    "    ev_data[name] = np.load(ev_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels (1000000,)\n",
      "lengths (1000000,)\n",
      "sketches (1000000, 300, 3)\n",
      "keys (1000000,)\n"
     ]
    }
   ],
   "source": [
    "for name, data in tr_data.items(): print(name, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels (1700000,)\n",
      "lengths (1700000,)\n",
      "sketches (1700000, 300, 3)\n",
      "keys (1700000,)\n"
     ]
    }
   ],
   "source": [
    "for name, data in ev_data.items(): print(name, data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
